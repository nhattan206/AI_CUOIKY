{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_CuoiKy_Test_Video.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYYYY7HsHUe+9gRct33V60",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhattan206/AI_CUOIKY/blob/main/AI_CuoiKy_Test_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SA7s-dLB5JF"
      },
      "outputs": [],
      "source": [
        "# TEST VIDEO\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "model = load_model('CuoiKy.h5')  # <-- Saved model path\n",
        "\n",
        "\n",
        "# input video file path\n",
        "input_file = 'video2.mp4'\n",
        "\n",
        "\n",
        "# output file path\n",
        "output_filename = 'testVideo_1.avi'  \n",
        "\n",
        "\n",
        "def get_points_main(img):\n",
        "\n",
        "    def detect_points(face_img):\n",
        "        me  = np.array(face_img)/255\n",
        "        x_test = np.expand_dims(me, axis=0)\n",
        "        x_test = np.expand_dims(x_test, axis=3)\n",
        "\n",
        "        y_test = model.predict(x_test)\n",
        "        label_points = (np.squeeze(y_test)*48)+48\n",
        "\n",
        "\n",
        "        return label_points\n",
        "\n",
        "    # load haarcascade\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "    dimensions = (96, 96)\n",
        "\n",
        "\n",
        "    try:\n",
        "        default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        gray_img = cv2.cvtColor(default_img, cv2.COLOR_RGB2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
        "#         faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
        "\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "    faces_img = np.copy(gray_img)\n",
        "\n",
        "    plt.rcParams[\"axes.grid\"] = False\n",
        "\n",
        "\n",
        "    all_x_cords = []\n",
        "    all_y_cords = []\n",
        "\n",
        "\n",
        "    for i, (x,y,w,h) in enumerate(faces):\n",
        "\n",
        "        h += 10\n",
        "        w += 10\n",
        "        x -= 5\n",
        "        y -= 5\n",
        "\n",
        "        try:\n",
        "            just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
        "        except:\n",
        "            return []\n",
        "        cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
        "\n",
        "        scale_val_x = w/96\n",
        "        scale_val_y = h/96\n",
        "\n",
        "        label_point = detect_points(just_face)\n",
        "\n",
        "        all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
        "        all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
        "\n",
        "\n",
        "\n",
        "    final_points_list = []\n",
        "    try:\n",
        "        for ii in range(len(all_x_cords)):\n",
        "            for a_x, a_y in zip(all_x_cords[ii], all_y_cords[ii]):\n",
        "                final_points_list.append([a_x, a_y])\n",
        "    except:\n",
        "        return final_points_list\n",
        "\n",
        "    return final_points_list\n",
        "\n",
        "# cap = cv2.VideoCapture(0)\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(input_file)\n",
        "ret, frame = cap.read()\n",
        "if not ret:\n",
        "    print(\"unavailable\")\n",
        "else:\n",
        "    height, width, channel = frame.shape\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "out = cv2.VideoWriter(output_filename, fourcc, 20.0, (width, height))\n",
        "\n",
        "\n",
        "frame_no = 0\n",
        "while cap.isOpened():\n",
        "\n",
        "    a = time.time()\n",
        "    \n",
        "    frame_no += 1\n",
        "    ret, frame = cap.read()\n",
        "    if frame_no > 75*30:\n",
        "        break\n",
        "    if frame_no in range(60*30, 75*30):\n",
        "        points = get_points_main(frame)\n",
        "\n",
        "        try:\n",
        "            overlay = frame.copy()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            break\n",
        "\n",
        "        for point in points:\n",
        "\n",
        "            cv2.circle(frame, tuple(point), 3, (255, 255, 255), -1)\n",
        "            # cv2.line(frame, last_point, tuple(point), (0,0,255), thickness=1)\n",
        "            # cv2.putText(overlay, str(i), tuple(point), 1, 1, (255, 255, 255))\n",
        "\n",
        "        if len(points) != 0:\n",
        "            o_line_points = [[12,13], [13,11], [11,14], [14,12], [12,10], [11,10], [10,3], [12,5], [11,3], [10,5], [10,4], [10,2], [5,1], [1,4], [2,0], [0,3], [5,9], [9,8], [8,4], [2,6], [6,7], [7,3]]\n",
        "            num_face = len(points)//15\n",
        "\n",
        "            for i in range(num_face):\n",
        "                line_points = np.array(o_line_points) + (15*(i))\n",
        "\n",
        "                the_color = (189, 195, 199)\n",
        "\n",
        "                for ii in line_points:\n",
        "                    cv2.line(overlay, tuple(points[ii[0]]), tuple(points[ii[1]]), the_color, thickness=1)\n",
        "\n",
        "\n",
        "        opacity = 0.3\n",
        "        cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)\n",
        "\n",
        "        out.write(frame)\n",
        "        # cv2.imshow('frame',frame)\n",
        "        b = time.time()\n",
        "        print(str((b-a)))\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "           \n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}